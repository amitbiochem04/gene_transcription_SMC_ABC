def MultipleTranscripts(T_i, a, alpha, tauOn, tauOff, tt):
    S = np.zeros((len(T_i), len(tt)))

    index = np.arange(0, len(T_i))
    for n in index:
        S[n, :] = singleTranscript(T_i[n], a, alpha, tauOn, tauOff, tt)
    return S.sum(axis = 0)


def CostInitiationEvents(T_i, a, alpha, tauOn, tauOff, signal, tt, error):
    S = MultipleTranscripts(T_i, a, alpha, tauOn, tauOff, tt)

    chi2 = np.sum(((signal - S) / (error[0] + error[1] * signal)) ** 2)

    return chi2


errCostInitiationEvents = lambda T_i, a, alpha, tauOn, tauOff, signal, tt, error:CostInitiationEvents(T_i, a,
                                                                                                      alpha, tauOn,
                                                                                                      tauOff, signal,
                                                                                                      tt, error)


def FitInitiationEvents(T_i_start, a, alpha, tauOn, tauOff, signal, tt, error):
    res = minimize(errCostInitiationEvents,
                   T_i_start,
                   args = (a, alpha, tauOn, tauOff, signal, tt, error),
                   method = 'SLSQP',
                   options = {'disp':False, 'maxiter':1e3, 'ftol':1e-3},
                   )
    return res


def FitInitialEventsBasin(T_i, a, alpha, tauOn, tauOff, signal, tt, error):
    res = sp.optimize.basinhopping(errCostInitiationEvents, T_i,
                                   minimizer_kwargs = dict(method = 'SLSQP',
                                                           args = (a, alpha, tauOn, tauOff, signal, tt, error)),
                                   disp = 'False',
                                   niter = 100,
                                   T = 0.7,
                                   niter_success = 5
                                   )
    return res


def FitSegments(windowSize, TranscriptInt, alpha, tauOn, tauOff, signal, tt, error, SingleTranscriptSignal):
    nWindows = len(tt) / windowSize
    windowStarts = np.arange(0, len(tt), windowSize)
    windowEnds = np.arange(windowSize - 1, len(tt), windowSize)
    n = 0
    res = []
    while n < nWindows:
        windowSignal = signal[windowStarts[n]:windowEnds[n]]
        windowTime = tt[windowStarts[n]:windowEnds[n]]
        windowSignalInt = np.trapz(signal[windowStarts[n]:windowEnds[n]], dx = tt[1] - tt[0])
        nWindowEvents = np.round(windowSignalInt / SingleTranscriptSignal)
        TiStart = sp.random.uniform(tt[windowStarts[n]], tt[windowEnds[n]], nWindowEvents)
        fit = FitInitiationEvents(TiStart, TranscriptInt, alpha, tauOn, tauOff, windowSignal, windowTime, error)
        res.append(fit.x)
        n = n + 1
    return res


def SortFittingResults(res):
    RES = []
    countOuter = 0
    countInner = 0
    while countOuter < len(res):
        while countInner < len(res[countOuter]):
            RES.append(res[countOuter][countInner])
            countInner = countInner + 1
        countOuter = countOuter + 1
        countInner = 0
    return RES


def MultipleStarts(windowSize, TranscriptIntensity, alpha, tauOn, tauOff, signal, tt, error, SingleTranscriptSignal,
                   nStarts, view):
    nEvents = np.trapz(signal, dx = tt[1] - tt[0]) / SingleTranscriptSignal
    nEvents = np.round(nEvents)

    res = np.zeros((nStarts, nEvents))

    WINDOWsize = np.zeros(nStarts) + windowSize
    TranscriptIntp = np.zeros(nStarts) + TranscriptIntensity
    ALPHA = np.zeros(nStarts) + alpha
    TAUon = np.zeros(nStarts) + tauOn
    TAUoff = np.zeros(nStarts) + tauOff
    SIGNAL = np.zeros((nStarts, len(signal))) + signal
    TT = np.zeros((nStarts, len(tt))) + tt
    ERROR = np.zeros((nStarts, 2)) + error
    SIINGLEtranscripSignal = np.zeros(nStarts) + SingleTranscriptSignal

    starts = view.map(FitSegments, WINDOWsize, TranscriptIntp, ALPHA, TAUon, TAUoff, SIGNAL, TT, ERROR,
                      SIINGLEtranscripSignal)

    index = np.arange(0, nStarts)
    for nn in index:
        start = starts[nn]
        start = SortFittingResults(start)
        if len(start) < nEvents:
            ti = sp.random.uniform(0, tt.max(), int(nEvents - len(start)))
            for t in ti:
                start.append(t)
        if len(start) > nEvents:
            ind = np.arange(0,len(start))
            ti = np.random.choice(ind,nEvents,replace = False)
            start = np.array(start)
            start = start[ti]
        res[nn, :] = start
    return res


def FitInitiationEventsDiffEvo(T_i, TranscriptIntensity, alpha, tauOn, tauOff, signal, tt, error):
    tmin = -2 * tauOff
    tmax = tt.max() + 2 * tauOff
    bnds = []
    bb = (tmin, tmax)
    for ti in T_i:
        bnds.append(bb)
    res = sp.optimize.differential_evolution(errCostInitiationEvents,
                                             bounds = bnds,
                                             args = (TranscriptIntensity, alpha, tauOn, tauOff, signal, tt, error),
                                             strategy = 'best1bin',
                                             popsize = 15,
                                             tol = 1e-1,
                                             mutation = (0.5, 1),
                                             recombination = 0.8,
                                             # seed = seed,
                                             disp = 'True',
                                             init = 'latinhypercube',
                                             polish = 'False'
                                             )
    return res


def FitInitialEventsMultiStart(Starts, TranscriptIntensity, alpha, tauOn, tauOff, signal, tt, error, view, method):
    TranscriptIntp = np.zeros(len(Starts)) + TranscriptIntensity
    ALPHA = np.zeros(len(Starts)) + alpha
    TAUon = np.zeros(len(Starts)) + tauOn
    TAUoff = np.zeros(len(Starts)) + tauOff
    SIGNAL = np.zeros((len(Starts), len(signal))) + signal
    TT = np.zeros((len(Starts), len(tt))) + tt
    ERROR = np.zeros((len(Starts), 2)) + error

    if method == 'local':
        fittingFunction = FitInitiationEvents
    else:
        fittingFunction = FitInitialEventsBasin
    fits = view.map(fittingFunction, Starts, TranscriptIntp, ALPHA, TAUon, TAUoff, SIGNAL, TT, ERROR)

    return fits


def InitialEventsMultiStart(windowSize, TranscriptIntensity, alpha, tauOn, tauOff, signal, tt,
                                 error, SingleTranscriptSignal, nStarts, view, method):
    print 'Inital guesses: started'
    Starts = MultipleStarts(windowSize, TranscriptIntensity,
                            alpha, tauOn, tauOff, signal, tt,
                            error, SingleTranscriptSignal,
                            nStarts, view)
    print 'Initial guesses: done'

    print 'Fitting: started'
    FITS = FitInitialEventsMultiStart(Starts, TranscriptIntensity, alpha, tauOn, tauOff, signal, tt, error, view, method)
    print 'Fitting: done'
    return FITS, Starts


def InitialEventsMultiStartMultiData(windowSize, TranscriptIntensity, alpha, tauOn, tauOff, Data, Mock, tt,
                                     SingleTranscriptSignal, nStarts, view, method):
    Res = []
    Starts = []
    index = np.arange(0, Data.shape[1])
    for nn in index:
        print 'cell ', nn + 1, ' of ', Data.shape[1]
        signal = Data[:, nn]
        mock = Mock[:, nn]
        error = [mock.std(), 0.1]
        FITS, starts = InitialEventsMultiStart(windowSize, TranscriptIntensity, alpha, tauOn, tauOff, signal, tt,
                                                    error, SingleTranscriptSignal, nStarts, view, method)
        Res.append(FITS)
        Starts.append(starts)
    return Res, Starts


def SaveData(path, Res, Starts):
    number = np.arange(0,len(Starts))
    for nn in number:
        np.save(path + 'Start_' + str(int(nn)), Starts[nn])
        index = np.arange(0,len(Starts[nn]))
        fit = np.zeros((len(Starts[nn]),len(Res[nn][0].x)))
        for n in index:
            fit[n] = Res[nn][n].x
        np.save(path + 'Fit_' + str(int(nn)), fit)

def CrossCorrelateAllData(DataTC, deltaT):
    '''
    Calculate cross correlations for all extracted signals
    :param DataTC: 2d array, time courses in columns
    :param deltaT: imaging time interval
    :return: 2d array with the cross correlations in columns
    '''
    res = np.zeros((2 * DataTC.shape[0] - 1, DataTC.shape[1] * (DataTC.shape[1] - 1)))
    col = 0
    signal1 = 0
    signal2 = 1
    while signal1 < DataTC.shape[1] - 1:
        while signal2 < DataTC.shape[1]:
            cc = scf.CrossCorrelate(DataTC[:, signal1], DataTC[:, signal2], deltaT)
            res[:, col] = cc[1]
            col = col + 1
            signal2 = signal2 + 1
        signal1 = signal1 + 1
        signal2 = signal1 + 1
    return cc[0], res


# calculate a confidence level on the ACF
def ACFconfidenceLevel(alpha, N):
    '''
    Calculate a confidence interval for the autocorrelation, i.e. all values of the autocorrelation above this
    values show a significant deviation.
    :param alpha: desired level, usually 95% => 0.95
    :param N: Number of data points
    :return:
    '''
    normDist = sp.stats.norm(loc = 0, scale = 1)
    x = sp.linspace(-5, 5, 1000)
    normCDF = normDist.cdf(x)
    index = np.where(normCDF >= (1 - alpha / 2))[0]
    level = normCDF[index[0]] / np.sqrt(N)
    return level
